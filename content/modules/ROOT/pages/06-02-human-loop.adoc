= Human In The Loop
include::_attributes.adoc[]
:slide:

**Human-in-the-Loop (HITL)** is an interaction pattern designed to enhance the capabilities of AI agents by involving human oversight at critical stages of the workflow. In complex scenarios, this approach allows developers to interrupt the agent’s execution, review its current state, and provide input or corrections before resuming. This process improves the reliability, accuracy, and safety of AI systems, making it especially useful for sensitive operations.

image::06/06-03-human-loop.png[Human in the Loop, scaledwidth="50%"]

## Common Human-in-the-Loop Interaction Patterns

1. **Approval**: The agent pauses at a predefined point in the workflow, allowing a user to review and approve actions before continuing. This is valuable for actions involving sensitive data or external tool calls.

2. **Editing**: Users can pause the agent, review its current state, and make edits if necessary. This helps correct potential mistakes before they impact the final output.

3. **Input Collection**: The workflow explicitly requests human input at specific nodes, integrating user-provided data directly into the agent’s decision-making process.

## Use-Cases for Human-in-the-Loop

- **Reviewing Tool Calls**: The agent pauses execution to allow users to review or modify the tool call parameters. This is particularly useful for ensuring accurate API requests or sensitive operations.

- **Time Travel**: Developers can replay or fork the agent’s past actions to debug decisions, explore alternative paths, or better understand the reasoning behind the agent’s choices.

## Enhancing Workflows with Persistence

LangGraph’s built-in **persistence** layer enables seamless human-in-the-loop interactions by saving checkpoints of the agent’s state at each step. This allows the workflow to pause for human input, then resume execution without losing progress. Checkpoints also support features like:

- **Breakpoints**: Define specific points in the graph where human input is required, ensuring critical actions are reviewed before proceeding.
- **Dynamic Breakpoints**: Interrupt the agent based on conditions, such as receiving input that doesn’t meet expected criteria, allowing for real-time intervention.

## Debugging with Time Travel

Human-in-the-loop also supports **time travel**, a powerful debugging concept that includes:

- **Replaying**: Reviewing the agent’s past actions from specific checkpoints to analyze the decision-making process.
- **Forking**: Editing a past state and creating a new path through the workflow, enabling exploration of alternative scenarios.

By incorporating human input at key stages, human-in-the-loop workflows improve the accuracy, safety, and flexibility of AI agents. This approach is crucial for applications where user oversight and manual adjustments are necessary to achieve reliable outcomes.
