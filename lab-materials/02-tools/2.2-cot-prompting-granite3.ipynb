{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "766aaa81-96e6-42dc-b29d-8216d2a7feec",
   "metadata": {},
   "source": [
    "## 2.2 - Chain of Thought Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5201cd-7664-4cf4-b329-af5aa69a5c76",
   "metadata": {},
   "source": [
    "**Chain of Thought** (CoT) is a concept in natural language processing (NLP) that enables \n",
    "language models to reason through tasks in a structured, step-by-step manner, similar to human \n",
    "thinking. Rather than generating isolated responses, a model using Chain of Thought builds on \n",
    "prior information, creating responses that follow a logical flow and ensuring a coherent, \n",
    "context-aware dialogue. This approach is particularly valuable in complex or multi-step queries,\n",
    "where understanding and maintaining context over multiple interactions is essential."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ece69d-0255-4232-9f1f-730a54b11453",
   "metadata": {},
   "source": [
    "## Why Chain of Thought Matters\n",
    "\n",
    "In traditional LLM models, responses can sometimes feel disjointed or context-free, especially with complex questions. Chain of Thought addresses these challenges by adding a reasoning layer, allowing the model to generate more accurate and relevant responses. This logical progression offers key benefits:\n",
    "\n",
    "1. **Coherence**: Responses follow a natural flow, making it easier for users to follow and engage with the conversation.\n",
    "2. **Context Retention**: By building on previous information, the model maintains context across multiple steps, crucial for handling complex questions.\n",
    "3. **Increased Accuracy**: Logical progression reduces the likelihood of irrelevant or incorrect information, enhancing the reliability of responses.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0022f3fb-ee50-40f2-b276-b8194668e49e",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a16ed2e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!pip install -q langchain==0.1.9 openai==1.13.3\n",
    "!pip install -q langchain-openai langchain\n",
    "#!pip uninstall langchain openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60bb3f0f-40b5-49a6-b493-5e361db0113e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import json\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from langchain.chains import LLMChain\n",
    "#from langchain_community.llms import VLLMOpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b908fd0-01dd-4ad2-b745-b3a4c56a7a7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "INFERENCE_SERVER_URL = os.getenv('API_URL_GRANITE')\n",
    "MODEL_NAME = \"granite30-8b\"\n",
    "API_KEY= os.getenv('API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472b2f3f-ac23-4531-984b-6e8357233992",
   "metadata": {},
   "source": [
    "### Create the LLM instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01baa2b8-529d-455d-ad39-ef4a96dbaf97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LLM definition\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=API_KEY,\n",
    "    openai_api_base= f\"{INFERENCE_SERVER_URL}/v1\",\n",
    "    model_name=MODEL_NAME,\n",
    "    top_p=0.92,\n",
    "    temperature=0.01,\n",
    "    max_tokens=512,\n",
    "    presence_penalty=1.03,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d211bd1f-3e55-41ce-b3bc-0ee5db689c66",
   "metadata": {},
   "source": [
    "### Create the Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdd8bc4c-b353-4a51-a8b7-6cb348e19623",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = \"\"\"\\\n",
    "<|start_of_role|>system<|end_of_role|>\n",
    "You are a helpful, respectful, and honest assistant. Always be as helpful as possible, while being safe. \n",
    "Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. \n",
    "Please ensure that your responses are socially unbiased and positive in nature.\n",
    "\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something incorrect. \n",
    "If you don't know the answer to a question, please don't share false information.\n",
    "<|end_of_text|>\n",
    "\n",
    "<|start_of_role|>user<|end_of_role|>\n",
    "Human: {input}\n",
    "<|end_of_text|>\n",
    "\n",
    "<|start_of_role|>assistant<|end_of_role|>\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(input_variables=[\"input\"], template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f875c62b-931a-402e-9494-98b7296f8b2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1129/2670321090.py:1: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  conversation = LLMChain(llm=llm,\n"
     ]
    }
   ],
   "source": [
    "conversation = LLMChain(llm=llm,\n",
    "                            prompt=PROMPT_LLM,\n",
    "                            verbose=False,\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969484f2-1f55-4021-a995-1d529cf9cc54",
   "metadata": {},
   "source": [
    "### Let's ask a simple question **WITHOUT** Chain of Thought in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee09847d-9ff7-4181-ad11-96186bf0a322",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " To design a financial report based on reports from larger Financial Services Institutions (FSIs), you should focus on key financial metrics such as revenue, net income, assets, liabilities, and equity. Additionally, consider analyzing their risk management strategies, investment portfolios, and operational efficiency. It's also beneficial to compare your institution's performance against the benchmarks set by these larger FSIs to identify areas for improvement and opportunities for growth. Furthermore, include an executive summary that provides an overview of the findings and any relevant conclusions or recommendations."
     ]
    }
   ],
   "source": [
    "first_input = \"I want to design a finantial report around the report from the larger FSIs. What I should focus?\"\n",
    "conversation.predict(input=first_input);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53514c74-27fd-48f7-8f74-dcc96b4856bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### LLM with Chain of Thought in the Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60ed6c44-a016-49bd-8623-f231c5bba5b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template=\"\"\"<s>[INST]<<SYS>>\n",
    "You are a helpful, respectful, and honest assistant. Always be as helpful as possible while being safe.\n",
    "You will be asked a question, to which you must give an answer.\n",
    "Your answer should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content.\n",
    "Please ensure that your responses are socially unbiased and positive in nature.\n",
    "When answering, think step-by-step and explain your reasoning before providing the final answer.\n",
    "Explain it with bullet points if it's needed but using reasoning and step-by-step.\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something incorrect.\n",
    "If you don't know the answer to a question, answer \"I don't know\".\n",
    "<</SYS>>\n",
    "\n",
    "### QUESTION:\n",
    "{input}\n",
    "\n",
    "### ANSWER:\n",
    "[/INST]\n",
    "\"\"\"\n",
    "PROMPT_COT = PromptTemplate(input_variables=[\"input\"], template=template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06992d19-a605-421b-a560-7082a3f12a6b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Chain of Thought Prompt\n",
    "\n",
    "Let's ask the same question with Chain of Thought\n",
    "\n",
    "* When answering, think step-by-step and explain your reasoning before providing the final answer.\n",
    "* Explain it with bullet points if it's needed but using reasoning and step-by-step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd3dba1b-7d9d-4c1f-b3f2-61b3385f7d7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conversation_cot = LLMChain(llm=llm,\n",
    "                            prompt=PROMPT_COT,\n",
    "                            verbose=False,\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98984cb8-b119-4770-a948-2779f211c519",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " To design a financial report based on the reports from larger Financial Services Institutions (FSIs), here are some key areas you should focus on:\n",
      "\n",
      "1. **Financial Statements**: Analyze the income statements, balance sheets, and cash flow statements of the FSIs. These statements provide a comprehensive overview of their financial performance, including revenue, expenses, assets, liabilities, and cash flow.\n",
      "\n",
      "2. **Key Performance Indicators (KPIs)**: Identify the KPIs that are commonly used by the FSIs and compare them with your own organization's performance. Some common KPIs include Return on Equity (ROE), Return on Assets (ROA), Net Interest Margin, and Efficiency Ratio.\n",
      "\n",
      "3. **Risk Management**: Examine the risk management practices of the FSIs. This includes their approach to credit risk, market risk, operational risk, and liquidity risk. Understanding these practices can help you identify potential risks in your own organization and develop strategies to mitigate them.\n",
      "\n",
      "4. **Regulatory Compliance**: Review the regulatory environment in which the FSIs operate and compare it with your own. This includes understanding the laws, regulations, and guidelines that apply to the financial services industry. Ensuring compliance with these regulations is crucial for maintaining a strong reputation and avoiding penalties.\n",
      "\n",
      "5. **Innovation and Technology**: Look at how the FSIs are leveraging technology to improve their operations, reduce costs, and enhance customer experience. This could include the use of artificial intelligence, blockchain, cloud computing, and mobile banking. Adopting similar technologies could help your organization stay competitive.\n",
      "\n",
      "6. **Market Trends**: Keep an eye on the broader trends in the financial services industry. This could include changes in consumer behavior, new products and services, and shifts in regulatory requirements. Understanding these trends can help you anticipate future challenges and opportunities.\n",
      "\n",
      "7. **Competitive Analysis**: Analyze the competitive landscape of the financial services industry. This includes identifying your competitors, understanding their strengths and weaknesses, and assessing your own competitive position. This information can help you make strategic decisions about product development, pricing, and marketing.\n",
      "\n",
      "8. **Stakeholder Analysis**: Consider the needs and expectations of your stakeholders, such as investors, customers, employees, and regulators. This could involve conducting surveys, focus groups,"
     ]
    }
   ],
   "source": [
    "first_input = \"I want to design a finantial report around the report from the larger FSIs. What I should focus?\"\n",
    "conversation_cot.predict(input=first_input);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06c4cad-c8c6-4368-80b9-1cc54195d20d",
   "metadata": {},
   "source": [
    "## Enhancing LLMs Performance with Chain of Thought\n",
    "\n",
    "By simulating a thought process, Chain of Thought enhances NLP models by:\n",
    "\n",
    "- **Improving Context Understanding**: The model remembers previous interactions, generating responses that are relevant and contextually aware.\n",
    "- **Boosting User Experience**: Users benefit from a more natural and satisfying interaction, as the model “thinks” through its responses.\n",
    "- **Increasing Flexibility**: CoT enables models to handle multi-part questions, making them versatile for applications like virtual assistants, customer service bots, and educational tools.\n",
    "\n",
    "Incorporating Chain of Thought into LLMs frameworks, such as LangChain, enables language models to tackle complex tasks, making them more effective for real-world applications where logical reasoning and clarity are paramount."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
